{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libs"
      ],
      "metadata": {
        "id": "JKeKdRJ3Bu-3"
      },
      "id": "JKeKdRJ3Bu-3"
    },
    {
      "cell_type": "code",
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2025-08-08T04:41:56.121490Z",
          "start_time": "2025-08-08T04:41:54.896437Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "initial_id",
        "outputId": "d22eebd2-2fdd-47bf-e75f-71c9f5650fb6"
      },
      "source": [
        "#Libs\n",
        "!pip install catboost\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "import joblib\n",
        "import os\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.11/dist-packages (1.2.8)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.16.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (8.5.0)\n"
          ]
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and Inspect Data"
      ],
      "metadata": {
        "id": "H5IZL9WBkii3"
      },
      "id": "H5IZL9WBkii3"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "# Inspect data\n",
        "print(train_df.head())\n",
        "print(train_df.info())\n",
        "print(train_df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7dVV0H3dKbP",
        "outputId": "fd796ab1-b488-460e-e41c-fda9ac6b617e"
      },
      "id": "F7dVV0H3dKbP",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ID                            fullAddress postcode  country outcode  \\\n",
            "0   0       38 Adelina Grove, London, E1 3AD   E1 3AD  England      E1   \n",
            "1   1      6 Cleveland Grove, London, E1 4XL   E1 4XL  England      E1   \n",
            "2   2   65 Sanderstead Road, London, E10 7PW  E10 7PW  England     E10   \n",
            "3   3  5 Queenswood Gardens, London, E11 3SE  E11 3SE  England     E11   \n",
            "4   4     12 Woodlands Road, London, E11 4RW  E11 4RW  England     E11   \n",
            "\n",
            "    latitude  longitude  bathrooms  bedrooms  floorAreaSqM  livingRooms  \\\n",
            "0  51.519406  -0.053261        NaN       3.0          80.0          1.0   \n",
            "1  51.521261  -0.053384        2.0       4.0         110.0          1.0   \n",
            "2  51.569054  -0.034892        1.0       3.0          84.0          1.0   \n",
            "3  51.564212   0.026292        NaN       2.0          72.0          1.0   \n",
            "4  51.563430   0.006260        1.0       3.0         104.0          1.0   \n",
            "\n",
            "      tenure         propertyType currentEnergyRating  sale_month  sale_year  \\\n",
            "0   Freehold  Semi-Detached House                   C           1       1995   \n",
            "1  Leasehold     Terrace Property                   D           1       1995   \n",
            "2   Freehold     Terrace Property                   D           1       1995   \n",
            "3  Leasehold   Purpose Built Flat                 NaN           1       1995   \n",
            "4   Freehold    Mid Terrace House                   D           1       1995   \n",
            "\n",
            "   price  \n",
            "0  77000  \n",
            "1  89995  \n",
            "2  59000  \n",
            "3  51500  \n",
            "4  63500  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 266325 entries, 0 to 266324\n",
            "Data columns (total 17 columns):\n",
            " #   Column               Non-Null Count   Dtype  \n",
            "---  ------               --------------   -----  \n",
            " 0   ID                   266325 non-null  int64  \n",
            " 1   fullAddress          266325 non-null  object \n",
            " 2   postcode             266325 non-null  object \n",
            " 3   country              266325 non-null  object \n",
            " 4   outcode              266325 non-null  object \n",
            " 5   latitude             266325 non-null  float64\n",
            " 6   longitude            266325 non-null  float64\n",
            " 7   bathrooms            217846 non-null  float64\n",
            " 8   bedrooms             241482 non-null  float64\n",
            " 9   floorAreaSqM         252519 non-null  float64\n",
            " 10  livingRooms          229285 non-null  float64\n",
            " 11  tenure               260604 non-null  object \n",
            " 12  propertyType         265817 non-null  object \n",
            " 13  currentEnergyRating  209511 non-null  object \n",
            " 14  sale_month           266325 non-null  int64  \n",
            " 15  sale_year            266325 non-null  int64  \n",
            " 16  price                266325 non-null  int64  \n",
            "dtypes: float64(6), int64(4), object(7)\n",
            "memory usage: 34.5+ MB\n",
            "None\n",
            "                  ID       latitude      longitude      bathrooms  \\\n",
            "count  266325.000000  266325.000000  266325.000000  217846.000000   \n",
            "mean   133162.000000      51.510090      -0.104639       1.439471   \n",
            "std     76881.549558       0.056709       0.088074       0.721365   \n",
            "min         0.000000      51.385708      -0.347055       1.000000   \n",
            "25%     66581.000000      51.466685      -0.159167       1.000000   \n",
            "50%    133162.000000      51.507202      -0.108622       1.000000   \n",
            "75%    199743.000000      51.550937      -0.049202       2.000000   \n",
            "max    266324.000000      51.665823       0.139249       9.000000   \n",
            "\n",
            "            bedrooms   floorAreaSqM    livingRooms     sale_month  \\\n",
            "count  241482.000000  252519.000000  229285.000000  266325.000000   \n",
            "mean        2.496140      99.624088       1.292160       6.805670   \n",
            "std         1.172209      56.454683       0.583029       3.356693   \n",
            "min         1.000000      10.000000       1.000000       1.000000   \n",
            "25%         2.000000      63.000000       1.000000       4.000000   \n",
            "50%         2.000000      85.000000       1.000000       7.000000   \n",
            "75%         3.000000     118.000000       1.000000      10.000000   \n",
            "max         9.000000     500.000000       9.000000      12.000000   \n",
            "\n",
            "           sale_year         price  \n",
            "count  266325.000000  2.663250e+05  \n",
            "mean     2012.213855  6.161788e+05  \n",
            "std         9.143113  1.274105e+06  \n",
            "min      1995.000000  1.000000e+04  \n",
            "25%      2004.000000  2.165000e+05  \n",
            "50%      2014.000000  3.850000e+05  \n",
            "75%      2021.000000  6.500000e+05  \n",
            "max      2023.000000  1.000000e+08  \n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "88a22686570cc478"
      },
      "cell_type": "markdown",
      "source": [
        "## Handling Missing Values"
      ],
      "id": "88a22686570cc478"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-08T04:41:56.806928Z",
          "start_time": "2025-08-08T04:41:56.746484Z"
        },
        "id": "bfa49bdcb964e8d8"
      },
      "cell_type": "code",
      "source": [
        "# Identify missing values (count and percentage)\n",
        "missing_counts = train_df.isnull().sum()\n",
        "missing_percent = (missing_counts / len(train_df)) * 100\n",
        "\n",
        "missing_df = pd.DataFrame({\n",
        "    'Missing Values': missing_counts,\n",
        "    'Percentage (%)': missing_percent\n",
        "}).sort_values(by='Missing Values', ascending=False)\n",
        "\n",
        "print(\"Missing Values Summary:\\n\", missing_df)\n",
        "\n",
        "# Visualise missing values\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(\n",
        "    x=missing_df.index,\n",
        "    y='Percentage (%)',\n",
        "    data=missing_df,\n",
        "    palette='viridis'\n",
        ")\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.title('Percentage of Missing Values by Column')\n",
        "plt.ylabel('Percentage (%)')\n",
        "plt.xlabel('Columns')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Heatmap to see missing value pattern\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(train_df.isnull(), cbar=False, cmap='viridis')\n",
        "plt.title('Missing Values Heatmap')\n",
        "plt.show()"
      ],
      "id": "bfa49bdcb964e8d8",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-08T04:41:57.075040Z",
          "start_time": "2025-08-08T04:41:56.955670Z"
        },
        "id": "98a5423306008ad3"
      },
      "cell_type": "code",
      "source": [
        "# Fill numarical columns with median\n",
        "numeric_cols = ['bathrooms', 'bedrooms', 'floorAreaSqM', 'livingRooms']\n",
        "for col in numeric_cols:\n",
        "    median_val = train_df[col].median()\n",
        "    train_df[col] = train_df[col].fillna(median_val)\n",
        "    test_df[col] = test_df[col].fillna(median_val)\n",
        "\n",
        "# Fill categorical columns with mode\n",
        "categorical_cols = ['tenure', 'propertyType', 'currentEnergyRating']\n",
        "for col in categorical_cols:\n",
        "    mode_val = train_df[col].mode()[0]\n",
        "    train_df[col] = train_df[col].fillna(mode_val)\n",
        "    test_df[col] = test_df[col].fillna(mode_val)"
      ],
      "id": "98a5423306008ad3",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-08T04:41:57.215207Z",
          "start_time": "2025-08-08T04:41:57.148016Z"
        },
        "id": "5ab7046d3392cc23"
      },
      "cell_type": "code",
      "source": [
        "print(train_df.isnull().sum())"
      ],
      "id": "5ab7046d3392cc23",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_cols = [\n",
        "    'bathrooms', 'bedrooms', 'floorAreaSqM',\n",
        "    'livingRooms', 'sale_month', 'sale_year', 'price'\n",
        "]\n",
        "\n",
        "train_df[numerical_cols].hist(\n",
        "    bins=30, figsize=(12, 8), edgecolor='black'\n",
        ")\n",
        "plt.suptitle(\"Histograms of Numerical Variables\", fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o_e-ffph2svr"
      },
      "id": "o_e-ffph2svr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "categorical_cols = ['tenure', 'propertyType', 'currentEnergyRating']\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "for i, col in enumerate(categorical_cols, 1):\n",
        "    plt.subplot(2, 2, i)\n",
        "    sns.countplot(\n",
        "        y=col,\n",
        "        data=train_df,\n",
        "        order=train_df[col].value_counts().index,\n",
        "        palette='viridis'\n",
        "    )\n",
        "    plt.title(f'Distribution of {col}')\n",
        "    plt.xlabel('Count')\n",
        "    plt.ylabel(col)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m3MrY5MW8J2s"
      },
      "id": "m3MrY5MW8J2s",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-08T04:41:57.294843Z",
          "start_time": "2025-08-08T04:41:57.284161Z"
        },
        "id": "323a256d1fb8736f"
      },
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "id": "323a256d1fb8736f",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing"
      ],
      "metadata": {
        "id": "8C8odJbt7Ugx"
      },
      "id": "8C8odJbt7Ugx"
    },
    {
      "cell_type": "code",
      "source": [
        "# Numerical variables to check for outliers\n",
        "numerical_vars = [\n",
        "    'bathrooms', 'bedrooms', 'floorAreaSqM',\n",
        "    'livingRooms', 'sale_month', 'sale_year', 'price'\n",
        "]\n",
        "\n",
        "# Plot boxplots\n",
        "plt.figure(figsize=(12, 8))\n",
        "for i, col in enumerate(numerical_vars, 1):\n",
        "    plt.subplot(3, 3, i)\n",
        "    sns.boxplot(x=train_df[col], color='skyblue')\n",
        "    plt.title(f'Boxplot of {col}')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-55ofdehawCg"
      },
      "id": "-55ofdehawCg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove Outliers"
      ],
      "metadata": {
        "id": "J_3rFlcPYQxA"
      },
      "id": "J_3rFlcPYQxA"
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove outliers beyond 3 standard deviations for price\n",
        "Q1 = train_df['price'].quantile(0.25)\n",
        "Q3 = train_df['price'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "train_df = train_df[(train_df['price'] >= Q1 - 1.5 * IQR) & (train_df['price'] <= Q3 + 1.5 * IQR)]"
      ],
      "metadata": {
        "id": "Vxq6DStKYTZp"
      },
      "id": "Vxq6DStKYTZp",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fba3b496371741d"
      },
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering"
      ],
      "id": "fba3b496371741d"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-08T04:41:58.253484Z",
          "start_time": "2025-08-08T04:41:57.434657Z"
        },
        "id": "477531614a38cf56"
      },
      "cell_type": "code",
      "source": [
        "def haversine_distance(lat1, lon1, lat2, lon2):\n",
        "    # Convert degrees to radians\n",
        "    lat1_rad = np.radians(lat1)\n",
        "    lon1_rad = np.radians(lon1)\n",
        "    lat2_rad = np.radians(lat2)\n",
        "    lon2_rad = np.radians(lon2)\n",
        "    # Compute differences in coordinates\n",
        "    delta_lat = lat2_rad - lat1_rad\n",
        "    delta_lon = lon2_rad - lon1_rad\n",
        "    # Apply the Haversine formula\n",
        "    sin_lat = np.sin(delta_lat / 2.0)\n",
        "    sin_lon = np.sin(delta_lon / 2.0)\n",
        "    a = sin_lat**2 + np.cos(lat1_rad) * np.cos(lat2_rad) * sin_lon**2\n",
        "    central_angle = 2 * np.arcsin(np.sqrt(a))\n",
        "    # Multiply by Earth's radius (in kilometers)\n",
        "    earth_radius_km = 6371.0\n",
        "    distance_km = earth_radius_km * central_angle\n",
        "    return distance_km\n",
        "\n",
        "landmarks = {\n",
        "    'centre':        (51.5074, -0.1278),   # Charing Cross\n",
        "    'city':          (51.5155, -0.0922),   # City of London\n",
        "    'canary_wharf':  (51.5054, -0.0235),   # Canary Wharf\n",
        "    'heathrow':      (51.4700, -0.4543),   # Heathrow Airport\n",
        "    'chelsea':       (51.4869, -0.1700),     # Chelsea\n",
        "    'mayfair':       (51.5116, -0.1478),      # mayfair\n",
        "    'knightsbridge': (51.4991, -0.1644),      # knightsbridge\n",
        "}\n",
        "\n",
        "for df in (train_df, test_df):\n",
        "    df['total_rooms'] = df['bedrooms'] + df['bathrooms'] + df['livingRooms']\n",
        "    df['property_age'] = df['sale_year'].max() - df['sale_year']\n",
        "    df['postcode_area'] = df['postcode'].str.extract(r'^([A-Za-z]{1,2})')\n",
        "    df['postcode_district'] = df['postcode'].str.extract(r'^[A-Za-z]{1,2}(\\d{1,2})')\n",
        "    for name, (lat_ref, lon_ref) in landmarks.items():\n",
        "        feature_name = f'dist_to_{name}'\n",
        "        df[feature_name] = haversine_distance(\n",
        "            df['latitude'], df['longitude'],\n",
        "            lat_ref, lon_ref\n",
        "        )\n"
      ],
      "id": "477531614a38cf56",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-08T04:41:58.350625Z",
          "start_time": "2025-08-08T04:41:58.334537Z"
        },
        "id": "82378535d74b56e6"
      },
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "id": "82378535d74b56e6",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "53716eb3fbe83cbc"
      },
      "cell_type": "markdown",
      "source": [
        "## Drop unnecessary columns"
      ],
      "id": "53716eb3fbe83cbc"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-08T04:41:58.583394Z",
          "start_time": "2025-08-08T04:41:58.545598Z"
        },
        "id": "5aede14d5a34dd7d"
      },
      "cell_type": "code",
      "source": [
        "drop_cols = ['ID', 'fullAddress', 'postcode', 'country', 'outcode', 'latitude',\n",
        "             'longitude', 'sale_month', 'sale_year']\n",
        "train_df = train_df.drop(columns=drop_cols, errors='ignore')\n",
        "test_df_ids = test_df['ID']\n",
        "test_df = test_df.drop(columns=drop_cols, errors='ignore')"
      ],
      "id": "5aede14d5a34dd7d",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.head())"
      ],
      "metadata": {
        "id": "6bqwyZoqhryZ"
      },
      "id": "6bqwyZoqhryZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "metadata": {
        "id": "GpMljUwrhvc1"
      },
      "id": "GpMljUwrhvc1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e685ab1169c7dc42"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare Data for Modeling"
      ],
      "id": "e685ab1169c7dc42"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-08T04:41:58.666787Z",
          "start_time": "2025-08-08T04:41:58.635094Z"
        },
        "id": "1974e6dbeab48b70"
      },
      "cell_type": "code",
      "source": [
        "# Separate features (X) and target variable (y)\n",
        "X = train_df.drop('price', axis=1)\n",
        "y = train_df['price']\n",
        "\n",
        "# One-hot encode categorical variables and drop the\n",
        "#first category to avoid dummy variable trap\n",
        "x_encoded_test = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    x_encoded_test, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Standardise the numerical features to have mean = 0 and standard deviation = 1\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled  = scaler.transform(X_test)"
      ],
      "id": "1974e6dbeab48b70",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and Test"
      ],
      "metadata": {
        "id": "8CvGFkn7PJum"
      },
      "id": "8CvGFkn7PJum"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try different models"
      ],
      "metadata": {
        "id": "lLtUBXnoc7Hc"
      },
      "id": "lLtUBXnoc7Hc"
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"LinearRegression\": LinearRegression(),\n",
        "    #\"SVR\": SVR(),\n",
        "    #\"DecisionTree\": DecisionTreeRegressor(random_state=42),\n",
        "    #\"RandomForest\": RandomForestRegressor(n_estimators=400, random_state=42, n_jobs=-1),\n",
        "    #\"XGBoost\": xgb.XGBRegressor(tree_method=\"hist\", n_estimators=500, random_state=42),\n",
        "    #\"LightGBM\": lgb.LGBMRegressor(n_estimators=500, random_state=42)\n",
        "}\n",
        "\n",
        "use_scaled = {\"LinearRegression\", \"SVR\"}\n",
        "\n",
        "def evaluate(model, Xtr, Xte, ytr, yte):\n",
        "    model.fit(Xtr, ytr)\n",
        "    pred = model.predict(Xte)\n",
        "    rmse = np.sqrt(mean_squared_error(yte, pred))\n",
        "    r2   = r2_score(yte, pred)\n",
        "    return rmse, r2\n",
        "\n",
        "rows = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    Xtr = X_train_scaled if name in use_scaled else X_train\n",
        "    Xte = X_test_scaled  if name in use_scaled else X_test\n",
        "    rmse, r2 = evaluate(model, Xtr, Xte, y_train, y_test)\n",
        "    rows.append({\"Model\": name, \"RMSE\": rmse, \"R2\": r2})\n",
        "\n",
        "results = pd.DataFrame(rows).sort_values(by=\"RMSE\")\n",
        "print(results.to_string(index=False))\n",
        "\n",
        "best = results.iloc[0]\n",
        "print(f\"\\nBest model: {best['Model']}  |  RMSE: {best['RMSE']:.2f}  |  R2: {best['R2']:.3f}\")"
      ],
      "metadata": {
        "id": "CQhDOT_XdeGa"
      },
      "id": "CQhDOT_XdeGa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Stacking Regressor"
      ],
      "metadata": {
        "id": "4PoOm1tEdaPh"
      },
      "id": "4PoOm1tEdaPh"
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_model = StackingRegressor(\n",
        "    estimators=[\n",
        "        ('xgb', XGBRegressor(random_state=42)),\n",
        "        ('lgbm', LGBMRegressor(random_state=42)),\n",
        "        ('cb', CatBoostRegressor(verbose=0, random_state=42)), # verbose=0 for cleaner output\n",
        "    ],\n",
        "    final_estimator=LinearRegression()\n",
        ")\n",
        "\n",
        "stacked_model.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "vdsMO687PLLl"
      },
      "id": "vdsMO687PLLl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "X9C0zCbtBsAY"
      },
      "id": "X9C0zCbtBsAY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = stacked_model.predict(X_test_scaled)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "accuracy_percent = r2 * 100\n",
        "\n",
        "\n",
        "# Display results\n",
        "print(f\"Model Name: {type(stacked_model).__name__}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
        "print(f\"R² Score: {r2}\")\n",
        "print(f\"Accuracy (%): {accuracy_percent}\")"
      ],
      "metadata": {
        "id": "nNc2qmebPdb6"
      },
      "id": "nNc2qmebPdb6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gEeji6wSPg9p"
      },
      "id": "gEeji6wSPg9p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Z6yH9RoPnM1"
      },
      "id": "-Z6yH9RoPnM1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-gIEl6rnX_U0"
      },
      "id": "-gIEl6rnX_U0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Scaling and Final Model"
      ],
      "metadata": {
        "id": "-YkY-uIjyo2_"
      },
      "id": "-YkY-uIjyo2_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export AI Model and Scaler"
      ],
      "metadata": {
        "id": "uh7dOsTTSB3T"
      },
      "id": "uh7dOsTTSB3T"
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "joblib.dump(stacked_model, 'stacked_model.pkl')\n",
        "\n",
        "# Save the fitted scaler\n",
        "joblib.dump(scaler, 'scaler.pkl')\n",
        "\n",
        "print(\"Model saved to stacked_model.pkl\")\n",
        "print(\"Scaler saved to scaler.pkl\")"
      ],
      "metadata": {
        "id": "SCLF_KDASw72"
      },
      "id": "SCLF_KDASw72",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "UeHVDQQcR8D0"
      },
      "id": "UeHVDQQcR8D0"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Encode test with the SAME dummies used for train ---\n",
        "test_X_encoded = pd.get_dummies(test_df, drop_first=True)\n",
        "\n",
        "# Align columns: add missing cols as 0, drop extras\n",
        "test_X_encoded = test_X_encoded.reindex(columns=x_encoded_test.columns, fill_value=0)\n",
        "\n",
        "# --- Scale with the SAME scaler used on train ---\n",
        "test_X_scaled = scaler.transform(test_X_encoded)\n",
        "\n",
        "# --- Predict with the trained stacked model ---\n",
        "test_preds = stacked_model.predict(test_X_scaled)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'ID': test_df_ids,\n",
        "    'price': test_preds\n",
        "})\n",
        "\n",
        "submission.to_csv('kaggle_submission.csv', index=False)\n",
        "print(\"Saved: kaggle_submission.csv\")"
      ],
      "metadata": {
        "id": "E6d2_1p3LJcs"
      },
      "id": "E6d2_1p3LJcs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export the training columns"
      ],
      "metadata": {
        "id": "pZihjy0wUweG"
      },
      "id": "pZihjy0wUweG"
    },
    {
      "cell_type": "code",
      "source": [
        "# === EXPORT ARTIFACTS FOR WEB APP (RUN ONCE) ===\n",
        "# This block saves:\n",
        "#  1) final_feature_columns.json  -> exact model input columns (order matters)\n",
        "#  2) training_refs.json          -> constants used in feature engineering (sale_year_max)\n",
        "#  3) landmarks.json              -> coordinates used to compute distance features\n",
        "#\n",
        "# Notes:\n",
        "# - It reads sale_year_max from the RAW train.csv to avoid KeyError if 'sale_year' was dropped.\n",
        "# - It expects your notebook already created `x_encoded_test` (encoded training features).\n",
        "\n",
        "import os, json\n",
        "import pandas as pd\n",
        "\n",
        "# ---- 0) Paths ----\n",
        "ART_DIR = \"artifacts\"\n",
        "RAW_TRAIN_PATH = \"train.csv\"   # change if your raw training file is elsewhere\n",
        "\n",
        "os.makedirs(ART_DIR, exist_ok=True)\n",
        "\n",
        "# ---- 1) Final model column order (must match training exactly) ----\n",
        "# Ensure x_encoded_test exists (the same columns were used for scaler/model training)\n",
        "try:\n",
        "    final_cols = x_encoded_test.columns.tolist()\n",
        "except NameError as e:\n",
        "    raise RuntimeError(\n",
        "        \"x_encoded_test is not defined. Please run the cell that creates \"\n",
        "        \"`x_encoded_test = pd.get_dummies(X, drop_first=True)` and aligns columns \"\n",
        "        \"before running this export block.\"\n",
        "    ) from e\n",
        "\n",
        "with open(f\"{ART_DIR}/final_feature_columns.json\", \"w\") as f:\n",
        "    json.dump(final_cols, f, indent=2)\n",
        "\n",
        "print(f\"[OK] Saved {ART_DIR}/final_feature_columns.json (n_cols={len(final_cols)})\")\n",
        "\n",
        "# ---- 2) Training constants used in feature engineering ----\n",
        "# We compute sale_year_max from the RAW dataset (before any drops),\n",
        "# so this works even if 'sale_year' was dropped in your working DataFrame.\n",
        "try:\n",
        "    train_raw = pd.read_csv(RAW_TRAIN_PATH)\n",
        "except FileNotFoundError as e:\n",
        "    raise RuntimeError(\n",
        "        f\"Could not read '{RAW_TRAIN_PATH}'. Set RAW_TRAIN_PATH to your raw training CSV.\"\n",
        "    ) from e\n",
        "\n",
        "if \"sale_year\" not in train_raw.columns:\n",
        "    raise RuntimeError(\n",
        "        \"Column 'sale_year' not found in the raw training CSV. \"\n",
        "        \"Please confirm your raw file path or the column name.\"\n",
        "    )\n",
        "\n",
        "sale_year_max = int(train_raw[\"sale_year\"].max())\n",
        "\n",
        "with open(f\"{ART_DIR}/training_refs.json\", \"w\") as f:\n",
        "    json.dump({\"sale_year_max\": sale_year_max}, f, indent=2)\n",
        "\n",
        "print(f\"[OK] Saved {ART_DIR}/training_refs.json (sale_year_max={sale_year_max})\")\n",
        "\n",
        "# ---- 3) Landmarks dictionary (use EXACT values you trained with) ----\n",
        "# Replace these with the same coordinates you used during training in this notebook.\n",
        "landmarks = {\n",
        "    \"centre\": [51.5074, -0.1278],\n",
        "    \"city\": [51.5136, -0.0890],\n",
        "    \"canary_wharf\": [51.5054, -0.0235],\n",
        "    \"heathrow\": [51.4700, -0.4543],\n",
        "    \"chelsea\": [51.4876, -0.1684],\n",
        "    \"mayfair\": [51.5090, -0.1490],\n",
        "    \"knightsbridge\": [51.5010, -0.1600],\n",
        "}\n",
        "\n",
        "with open(f\"{ART_DIR}/landmarks.json\", \"w\") as f:\n",
        "    json.dump(landmarks, f, indent=2)\n",
        "\n",
        "print(f\"[OK] Saved {ART_DIR}/landmarks.json (keys={list(landmarks.keys())})\")\n",
        "\n",
        "print(\"\\nAll export artifacts are ready in the 'artifacts' folder.\")\n"
      ],
      "metadata": {
        "id": "C7APgBGOUzVO"
      },
      "id": "C7APgBGOUzVO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, sklearn, numpy, scipy\n",
        "print(\"Python:\", sys.version)\n",
        "print(\"sklearn:\", sklearn.__version__)\n",
        "print(\"numpy:\", numpy.__version__)\n",
        "print(\"scipy:\", scipy.__version__)"
      ],
      "metadata": {
        "id": "H4MZQPM3ckak"
      },
      "id": "H4MZQPM3ckak",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "JKeKdRJ3Bu-3",
        "H5IZL9WBkii3",
        "88a22686570cc478",
        "8C8odJbt7Ugx"
      ],
      "gpuType": "T4",
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}